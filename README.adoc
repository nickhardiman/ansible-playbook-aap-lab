= Ansible playbook for turning a PC into a set of Ansible Automation Platform VMs

!!! this description is mostly outdated pants. 

Ansible helps me build my home lab. 
This playbook turns a PC running RHEL 9 into a hypervisor running a pile-load (that's the technical term) of Virtual Machines. 
Each VM runs a set of services that support my home lab. 

Idea is to build the 
Ansible Automation Platform 2
Reference Architecture. 

https://access.redhat.com/documentation/en-us/reference_architectures/2021/html-single/deploying_ansible_automation_platform_2.1/index#doc-wrapper


Under construction. Sections marked with !!! and ??? are notes to self. 

Ansible helps me build my home lab. 
This playbook turns three PCs into a distributed automation platform.
Each PC runs RHEL 9, a hypervisor, a pile-load (that's the technical term) of Virtual Machines, and many applications.

Architecture is based on the 
https://access.redhat.com/documentation/en-us/reference_architectures/2021/html-single/deploying_ansible_automation_platform_2.1/index#doc-wrapper[Ansible Automation Platform Reference Architecture].

The home lab allows me to emulate a complex IT estate, like you might find in a large organization.

== physical machines

I work from a regular laptop on my home network.
The AAP home lab runs on three PCs.
Each PC emulates a geographical site 
* workstation 
* site 1, primary AAP cluster
* site 2, secondary AAP cluster
* site 3, supporting services (LDAP, git, DNS, and so on)

== networks

Three networks are involved in making this home lab work.

* home lab
* home network
* Internet

Three PCs provide the physical platform for my home lab, and are connected to my home network. 
The home network is an ordinary domestic network managed by the magic box my ISP provided.
The home network is the collection of router, WiFI antennas, TV, mobile phone and other devices.
The ISP router provides access to the Internet, so this AAP installation can connect to Red Hat's central services.
For instance, RPM packages are downloaded from the Red Hat CDN.
The home lab has its own networks.

Each home lab machine contains two virtual networks. 
One is for public access. This connects to the home lab, and via there to the Internet.
The other network is private, with all the VMs connected to it. 
Access is restricted. 
These VMs can only get to the Internet via a proxy running on the gateway.
I connect to web services on these VMs via a reverse proxy running on the gateway.



== site 1, primary AAP cluster

. *gateway*, a proxy with interfaces on the public and private networks. Also provides utilities. !!! move NFS to misc-rhel8?
. *controlplane-1*, a control plane node in the Automation Controller cluster
. *controlplane-2*
. *controlplane-3*
. *controlplane-db*, a Postgres database for the Automation Controller !!! change to "rdbms", one central postgresql server
. *automationhub-1*, a hub node in the Private Automation Hub cluster. This mounts an NFS share from gateway.
. *automationhub-2*
. *automationhub-3*
. *automationhub-db*, a Postgres database for the Private Automation Hub !!! change to "automationedacontroller"
. *executionnode-1*, an execution plane node 
. *executionnode-2*
. *misc-rhel8*, RH-SSO and other RHEL 8 applications.

=== physical machine

=== OS (Operating System)

=== the KVM/QEMU hypervisor 

A bootstrap shell script kicks off the install. 
See instructions in 
https://github.com/nickhardiman/ansible-playbook-lab/blob/main/machine-hypervisor.sh[machine-hypervisor.sh]


=== virtual network

networks 

* home network
* home lab

Each machine has two networks. 
One is for public access from elsewhere in the network. 
The other is private, for all the VMs.

* 192.168.20.0/24 - public network on the site1 PC
* 192.168.21.0/24 - private network on the site1 PC
* 192.168.22.0/24 - public network on the site2 PC
* 192.168.23.0/24 - private network on the site2 PC
* 192.168.24.0/24 - public network on the site3 PC
* 192.168.25.0/24 - private network on the site3 PC


=== VMs 

The https://github.com/nickhardiman/ansible-playbook-aap2-refarch/blob/main/group_vars/all/main.yml[defaults file] defines a lot of values. 
For instance, most 
MAC addresses are set to ** 52:54:00:04:00:* **,  and 
IPv4 addresses are set to ** 192.168.21.* **. 
Check out DHCP's 
https://github.com/nickhardiman/ansible-collection-platform/blob/main/roles/dhcp_server/templates/dhcpd.conf.j2[config].

bridges

* brpublic0
* brsite0

.guests attached to bridges
[%header,format=csv]
|===
name,         interface, MAC,               IP,              domain
*netpublic0*,    *brpublic0*,    52:54:00:03:00:01, 192.168.1.1,     site1.home
gateway,      enp1s0,    52:54:00:03:00:03, 192.168.1.3,     site1.home

*netlab0*,  *brlab0*,   52:54:00:04:00:01, 192.168.21.1,   site1.example.com
 ,           ,           52:54:00:04:00:02, 192.168.21.2,   site1.example.com
gateway,          enp2s0,    52:54:00:04:00:03, 192.168.21.3,   site1.example.com
controlplane-1,   enp1s0,    52:54:00:04:00:10, 192.168.21.10,   site1.example.com
controlplane-2,   enp1s0,    52:54:00:04:00:11, 192.168.21.11,   site1.example.com
controlplane-3,   enp1s0,    52:54:00:04:00:12, 192.168.21.12,   site1.example.com
controlplane-db,  enp1s0,    52:54:00:04:00:13, 192.168.21.13,   site1.example.com
               ,  enp1s0,    52:54:00:04:00:14, 192.168.21.14,   site1.example.com
executionnode-1,  enp1s0,    52:54:00:04:00:15, 192.168.21.15,   site1.example.com
executionnode-2,  enp1s0,    52:54:00:04:00:16, 192.168.21.16,   site1.example.com
automationhub-1,  enp1s0,    52:54:00:04:00:17, 192.168.21.17,   site1.example.com
automationhub-2,  enp1s0,    52:54:00:04:00:18, 192.168.21.18,   site1.example.com
automationhub-3,  enp1s0,    52:54:00:04:00:19, 192.168.21.19,   site1.example.com
automationhub-db, enp1s0,    52:54:00:04:00:20, 192.168.21.20,   site1.example.com
misc-rhel8      , enp1s0,    52:54:00:04:00:21, 192.168.21.21,   site1.example.com
|===


== site 2, secondary AAP cluster

A duplicate of site 1.

. *gateway*, a proxy with interfaces on the public and private networks. Also provides utilities.
. *controlplane-1*, a control plane node in the Automation Controller cluster
. *controlplane-2*
. *controlplane-3*
. *controlplane-db*, a Postgres database for the Automation Controller !!! change to "rdbms", one central postgresql server
. *automationhub-1*, a hub node in the Private Automation Hub cluster. This mounts an NFS share from gateway.
. *automationhub-2*
. *automationhub-3*
. *automationhub-db*, a Postgres database for the Private Automation Hub !!! change to "automationedacontroller"
. *executionnode-1*, an execution plane node 
. *executionnode-2*
. *misc-rhel8*, RH-SSO and other RHEL 8 applications.


== site 3, supporting services 

LDAP, git, DNS, and so on.

. *gateway*, a proxy with interfaces on the public and private networks. Also provides utilities.


== cheatsheet 

AAP install 

manual instructions
 https://access.redhat.com/documentation/en-us/reference_architectures/2021/html-single/deploying_ansible_automation_platform_2.1/index

quite a bit to do 

=== PC and OS

Start with a machine running RHEL 9.
A fresh minimal install is fine.

Only tested on a box with one ethernet interface, plugged into the network.


=== install dependencies

Script
https://raw.githubusercontent.com/nickhardiman/ansible-playbook-lab/main/machine-hypervisor.sh[machine-hypervisor.sh]
sets up everything on a freshly installed host.
This works with RHEL and Fedora.
Some things, like that "dnf install" line, won't work on other OSs.

* Log into the hypervisor machine.
* Download the script.

[source,shell]
....
curl -O https://raw.githubusercontent.com/nickhardiman/ansible-playbook-lab/main/machine-hypervisor.sh 
....

* Read the script and follow the instructions.


The script creates a new user named _ansible_user_
along with a key pair named _ansible-key.priv_ and _ansible-key.pub_
and sudoers privilege escalation.
The playbook uses _ansible_user_ to connect to all the machines,

The script also clones the playbook repo and installs dependencies.



=== add Red Hat Subscription account to the vault

Each new VM will connect to the RHSM (Red Hat Subscription Management) network,
register, attach a subscription entitlement, and download from
Red Hat's CDN (Content Delivery Network).

* Sign up for free at https://developers.redhat.com/.
* Check your account works by logging in at https://access.redhat.com/.
* Edit the vault file.
* Enter your Red Hat Subscription Manager account.
* Encrypt the file.

[source,shell]
....
vim vault-credentials.yml
echo 'my vault password' >  ~/my-vault-pass
ansible-vault encrypt --vault-pass-file ~/my-vault-pass vault-credentials.yml  
....


=== AAP prereqs

* get install bundle
* inventory, credentials vault (see files)
* firewall ports 
* create NFS share on gateway 

[source,shell]
....
# https://www.redhat.com/sysadmin/configure-nfs-linux
systemctl enable --now nfs-server
dnf install nfs-utils
systemctl enable --now rpcbind
mkdir -p /var/nfs/exports/pulp
chown root:ansible_user /var/nfs/exports/pulp 
chmod 775 root:ansible_user /var/nfs/exports/pulp 
echo '/var/nfs/exports/pulp 192.168.0.0/16(rw,no_root_squash)' >> /etc/exports
exportfs -r
firewall-cmd --add-service nfs --permanent
firewall-cmd --add-service nfs
....

* create NFS mount on hubs 

[source,shell]
....
sudo mkdir /var/lib/pulp
dnf install nfsv4-client-utils.x86_64
mount -v -t nfs4 192.168.21.3:/var/nfs/exports/pulp /var/lib/pulp
....

* ??? add proxy env vars for hubs to download containers
* !!! no, maybe login is non-interactive. /etc/environment?
* ??? add proxy env vars for controller to download manifest
*     in /etc/profile.d/http_proxy.sh 


=== Install AAP

* copy files/credentials-controlplane-plaintext.yml to credentials-controlplane.yml 
* add sensitive details
* encrypt
*  Install controller.

[source,shell]
....
ANSIBLE_PRIVATE_KEY_FILE=~/.ssh/ansible-key.priv \
ANSIBLE_REMOTE_USER=ansible_user \
ANSIBLE_BECOME=True \
ANSIBLE_HOST_KEY_CHECKING=False \
./setup.sh -e @credentials-controlplane.yml --  \
  --vault-pass-file=~/vault-password.txt
....

* !!! copy files/credentials-hub-plaintext.yml, add sensitive details, encrypt
*  Install hub. 
 proxy settings are for internet downloads of container images. 
 Installer doesn't download collections.

[source,shell]
....
ANSIBLE_PRIVATE_KEY_FILE=~/.ssh/ansible-key.priv \
ANSIBLE_REMOTE_USER=ansible_user \
ANSIBLE_BECOME=True \
ANSIBLE_HOST_KEY_CHECKING=False \
./setup.sh \
 -e @credentials_hub.yml \
 -e 'http_proxy=http://gateway.site1.example.com:3128' \
 -e 'https_proxy=http://gateway.site1.example.com:3128' \
 -e 'no_proxy=localhost,127.0.0.1,example.com' \
 --  \
 --vault-pass-file=~/vault-password.txt
....

